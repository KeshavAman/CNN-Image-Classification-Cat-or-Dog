{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN on cat and dog.ipynb",
      "provenance": [],
      "mount_file_id": "1_iFLJoIY1Vhia18ZB9ZB6IZreoeL9gEX",
      "authorship_tag": "ABX9TyNexMUFw3GaaTER5Hx8JiWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeshavAman/CNN-Image-Classification-Cat-or-Dog/blob/main/CNN_on_cat_and_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPGeFLDUmlnc"
      },
      "source": [
        "**Get acess google drive data into google colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkakR3lBgZ42",
        "outputId": "2b1ebc0a-b765-490a-f48f-aba37f69dd48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbvS9dE6lwWS",
        "outputId": "9b3777b9-3ee7-4fad-8369-f342959149ce"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/dataset.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxzQ5pEDnNzd"
      },
      "source": [
        "**Importing the Keras libraries and packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZTZ0G2YnDyL"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SH28qUooGBv"
      },
      "source": [
        "**Initialising the CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKg91iosoA8M"
      },
      "source": [
        "CNN_Classifier = Sequential()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pKWW_3CoTZM"
      },
      "source": [
        "**Convolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmUxBATWoQxg"
      },
      "source": [
        "CNN_Classifier.add(Conv2D(32,(3,3), input_shape = (64,64,3), activation= 'relu'))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le0DXubBo7pm"
      },
      "source": [
        "**Pooling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx7u23wFo41e"
      },
      "source": [
        "CNN_Classifier.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg0y-24ApMGJ"
      },
      "source": [
        "**Repeat Convolution and Pooling again**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZJd9wWfpK46"
      },
      "source": [
        "CNN_Classifier.add(Conv2D(16,(3,3), activation= 'relu'))\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW7rD4IkpkXW"
      },
      "source": [
        "**Flattening**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EEXoGQKpjcY"
      },
      "source": [
        "CNN_Classifier.add(Flatten())"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGjbKmfPpy5O"
      },
      "source": [
        "**Full Connection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8a4Va6NpxSH"
      },
      "source": [
        "CNN_Classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "CNN_Classifier.add(Dense(units =1, activation = 'sigmoid'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl66kSgxqMwk"
      },
      "source": [
        "**Compiling the CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "desqo0cYqMAh"
      },
      "source": [
        "CNN_Classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics ='accuracy')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMMqX3y4q7J1"
      },
      "source": [
        "**Preprocessing and Fitting the CNN to image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzozkxOIrTpL",
        "outputId": "4604dd51-8b73-41f3-cfb9-1877a426b4b8"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_set = train_datagen.flow_from_directory('/content/dataset/training_set', target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "test_set = test_datagen.flow_from_directory('/content/dataset/test_set', target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "CNN_Classifier.fit_generator(train_set, steps_per_epoch=8000/32, epochs=20, validation_data=test_set, validation_steps=2000/32)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 37s 146ms/step - loss: 0.6861 - accuracy: 0.5539 - val_loss: 0.6782 - val_accuracy: 0.5610\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 36s 145ms/step - loss: 0.6644 - accuracy: 0.6056 - val_loss: 0.6367 - val_accuracy: 0.6270\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 36s 143ms/step - loss: 0.6231 - accuracy: 0.6563 - val_loss: 0.6072 - val_accuracy: 0.6580\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 36s 144ms/step - loss: 0.5974 - accuracy: 0.6848 - val_loss: 0.5924 - val_accuracy: 0.6935\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 36s 145ms/step - loss: 0.5815 - accuracy: 0.6980 - val_loss: 0.5759 - val_accuracy: 0.7115\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 36s 144ms/step - loss: 0.5553 - accuracy: 0.7057 - val_loss: 0.5650 - val_accuracy: 0.7190\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 36s 143ms/step - loss: 0.5273 - accuracy: 0.7325 - val_loss: 0.5242 - val_accuracy: 0.7445\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 36s 143ms/step - loss: 0.5209 - accuracy: 0.7413 - val_loss: 0.5098 - val_accuracy: 0.7630\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.4927 - accuracy: 0.7557 - val_loss: 0.5233 - val_accuracy: 0.7460\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.4884 - accuracy: 0.7648 - val_loss: 0.5235 - val_accuracy: 0.7550\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.4577 - accuracy: 0.7789 - val_loss: 0.4971 - val_accuracy: 0.7625\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.4478 - accuracy: 0.7898 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.4336 - accuracy: 0.7997 - val_loss: 0.5107 - val_accuracy: 0.7570\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.4204 - accuracy: 0.8031 - val_loss: 0.5232 - val_accuracy: 0.7645\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.4130 - accuracy: 0.8179 - val_loss: 0.4977 - val_accuracy: 0.7785\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 35s 141ms/step - loss: 0.4081 - accuracy: 0.8067 - val_loss: 0.4855 - val_accuracy: 0.7775\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.3863 - accuracy: 0.8231 - val_loss: 0.5034 - val_accuracy: 0.7630\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.3740 - accuracy: 0.8282 - val_loss: 0.5186 - val_accuracy: 0.7825\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.3617 - accuracy: 0.8420 - val_loss: 0.5349 - val_accuracy: 0.7530\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 35s 140ms/step - loss: 0.3510 - accuracy: 0.8444 - val_loss: 0.5083 - val_accuracy: 0.7630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ed73b2e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jodhe2rs0If-"
      },
      "source": [
        "**Example prediction for Dog image using train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYr8NpEdxlO-",
        "outputId": "63d17d67-0c51-45db-cf1c-91b0c40a7b39"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = CNN_Classifier.predict(test_image)\n",
        "training_set.class_indices"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cats': 0, 'dogs': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_N5vg-18GAE",
        "outputId": "55b4ca17-bbc3-4870-8657-c530930513d0"
      },
      "source": [
        "if result[0][0] == 1:\n",
        "    print('Dog')\n",
        "else:\n",
        "    print('Cat')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}